{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import uuid\n",
    "\n",
    "def something_complex(var):\n",
    "    time.sleep(0.0001)\n",
    "    return var ** 2\n",
    "\n",
    "import functools\n",
    "\n",
    "def exec_time(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_decorator(*args, **kwargs):\n",
    "        # Do something before\n",
    "        t0 = time.time()\n",
    "        value = func(*args, **kwargs)\n",
    "        t1 = time.time()\n",
    "        print(f'execution took {t1-t0:.2f}s')\n",
    "        return value\n",
    "    return wrapper_decorator\n",
    "\n",
    "    \n",
    "class Foo:\n",
    "    _cache_property = None\n",
    "    \n",
    "    def __init__(self, *args, list_size, complexity=100000, **kwargs):\n",
    "        self.list_size = list_size\n",
    "        self.complexity = complexity\n",
    "        self.cache_fname = f'cache-{complexity}.pkl'\n",
    "        \n",
    "    @property\n",
    "    def input_list(self):\n",
    "        # strategy for a property - very efficient but will never update. assumes that data never changes.\n",
    "        if self._cache_property is None:\n",
    "            self._cache_property = [int(random.random() * self.complexity) for i in range(self.list_size)]\n",
    "            \n",
    "        return self._cache_property\n",
    "    \n",
    "    def create_new_input_list(self):\n",
    "        self._cache_property = None\n",
    "        return self.input_list\n",
    "    \n",
    "    @exec_time\n",
    "    def complex_loop(self):\n",
    "        print('starting naive loop')\n",
    "        result = 0\n",
    "        for i in self.input_list:\n",
    "            result += something_complex(i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @exec_time\n",
    "    def make_complex_loop_faster(self):\n",
    "        print('starting cached loop')      \n",
    "        my_cache = {}\n",
    "        result = 0\n",
    "        for i in self.input_list:\n",
    "            res = my_cache.get(i)\n",
    "            if res is None:\n",
    "                res =  something_complex(i)\n",
    "                my_cache[i] = res\n",
    "            result += res\n",
    "        \n",
    "        return result    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Foo(list_size=10000, complexity=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting naive loop\n",
      "execution took 3.14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32341861"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.complex_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting cached loop\n",
      "execution took 0.06s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32341861"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.make_complex_loop_faster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complex example: a persistent cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import uuid\n",
    "\n",
    "def something_complex(var):\n",
    "    time.sleep(0.0001)\n",
    "    return var ** 2\n",
    "\n",
    "import functools\n",
    "\n",
    "def exec_time(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_decorator(*args, **kwargs):\n",
    "        # Do something before\n",
    "        t0 = time.time()\n",
    "        value = func(*args, **kwargs)\n",
    "        t1 = time.time()\n",
    "        print(f'execution took {t1-t0:.2f}s')\n",
    "        return value\n",
    "    return wrapper_decorator\n",
    "\n",
    "    \n",
    "class Foo:\n",
    "    _cache_property = None\n",
    "    \n",
    "    def __init__(self, *args, list_size, complexity=100000, **kwargs):\n",
    "        self.list_size = list_size\n",
    "        self.complexity = complexity\n",
    "        self.cache_fname = f'cache-{complexity}.pkl'\n",
    "        \n",
    "    @property\n",
    "    def input_list(self):\n",
    "        # strategy for a property - very efficient but will never update. assumes that data never changes.\n",
    "        if self._cache_property is None:\n",
    "            self._cache_property = [int(random.random() * self.complexity) for i in range(self.list_size)]\n",
    "            \n",
    "        return self._cache_property\n",
    "    \n",
    "    def create_new_input_list(self):\n",
    "        self._cache_property = None\n",
    "        return self.input_list\n",
    "    \n",
    "    @exec_time\n",
    "    def complex_loop(self):\n",
    "        print('starting naive loop')\n",
    "        result = 0\n",
    "        for i in self.input_list:\n",
    "            result += something_complex(i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @exec_time\n",
    "    def make_complex_loop_faster(self):\n",
    "        print('starting cached loop')      \n",
    "        my_cache = {}\n",
    "        result = 0\n",
    "        for i in self.input_list:\n",
    "            res = my_cache.get(i)\n",
    "            if res is None:\n",
    "                res =  something_complex(i)\n",
    "                my_cache[i] = res\n",
    "            result += res\n",
    "        \n",
    "        return result    \n",
    "    \n",
    "    def get_cache(self, delete_cache: bool=False):\n",
    "\n",
    "        if delete_cache  and os.path.isfile(self.cache_fname):\n",
    "            os.remove(self.cache_fname)\n",
    "            \n",
    "        if os.path.isfile(self.cache_fname):\n",
    "            with open(self.cache_fname, 'rb') as pfile:\n",
    "                my_cache = pickle.load(pfile)\n",
    "        else:\n",
    "            my_cache = {}\n",
    "            \n",
    "        return my_cache\n",
    "        \n",
    "    def dump_cache(self, my_cache):\n",
    "        with open(self.cache_fname, 'wb') as pfile:\n",
    "            pickle.dump(my_cache, pfile)\n",
    "            \n",
    "    def analyze_cache(self):\n",
    "        cache = self.get_cache()\n",
    "        uniques = len(set(cache.keys()))\n",
    "        print(f'{uniques} keys in cache - max {self.complexity}')\n",
    "        \n",
    "    @exec_time\n",
    "    def using_a_persistent_cache(self, delete_cache=False):\n",
    "        print('starting (persistant) cached loop')        \n",
    "            \n",
    "        my_cache = self.get_cache(delete_cache=delete_cache)\n",
    "            \n",
    "        result = 0\n",
    "        for i in self.input_list:\n",
    "            res = my_cache.get(i)\n",
    "            if res is None:\n",
    "                res =  something_complex(i)\n",
    "                my_cache[i] = res\n",
    "            result += res\n",
    "            \n",
    "        \n",
    "        self.dump_cache(my_cache)\n",
    "          \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(n):\n",
    "    new = Bar(list_size=n)\n",
    "    return new.using_a_distributed_persistent_cache()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForkPoolWorker-24] starting (distributed, persistant) cached loop\n",
      "Cache loaded with 100000 items\n",
      "empty cache, not writing\n",
      "ForkPoolWorker-24] end\n",
      "execution took 6.37s\n",
      "ForkPoolWorker-24] starting (distributed, persistant) cached loop\n",
      "Cache loaded with 100000 items\n",
      "empty cache, not writing\n",
      "ForkPoolWorker-24] end\n",
      "execution took 6.47s\n",
      "ForkPoolWorker-24] starting (distributed, persistant) cached loop\n",
      "Cache loaded with 100000 items\n",
      "empty cache, not writing\n",
      "ForkPoolWorker-24] end\n",
      "execution took 6.56s\n",
      "ForkPoolWorker-24] starting (distributed, persistant) cached loop\n",
      "Cache loaded with 100000 items\n",
      "empty cache, not writing\n",
      "ForkPoolWorker-24] end\n",
      "execution took 6.41s\n",
      "ForkPoolWorker-24] starting (distributed, persistant) cached loop\n",
      "Cache loaded with 100000 items\n",
      "empty cache, not writing\n",
      "ForkPoolWorker-24] end\n",
      "execution took 6.25s\n",
      "ForkPoolWorker-24] starting (distributed, persistant) cached loop\n",
      "Cache loaded with 100000 items\n",
      "empty cache, not writing\n",
      "ForkPoolWorker-24] end\n",
      "execution took 6.62s\n",
      "ForkPoolWorker-24] starting (distributed, persistant) cached loop\n",
      "Cache loaded with 100000 items\n",
      "empty cache, not writing\n",
      "ForkPoolWorker-24] end\n",
      "execution took 6.43s\n",
      "ForkPoolWorker-24] starting (distributed, persistant) cached loop\n",
      "Cache loaded with 100000 items\n",
      "empty cache, not writing\n",
      "ForkPoolWorker-24] end\n",
      "execution took 6.78s\n",
      "ForkPoolWorker-24] starting (distributed, persistant) cached loop\n",
      "Cache loaded with 100000 items\n",
      "empty cache, not writing\n",
      "ForkPoolWorker-24] end\n",
      "execution took 6.82s\n",
      "ForkPoolWorker-24] starting (distributed, persistant) cached loop\n",
      "Cache loaded with 100000 items\n",
      "empty cache, not writing\n",
      "ForkPoolWorker-24] end\n",
      "execution took 6.38s\n"
     ]
    }
   ],
   "source": [
    "pool = mp.Pool(processes=1)\n",
    "processes = []\n",
    "for i in range(10):\n",
    "    processes.append(pool.apply_async(run, (10000000, )))\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "final = sum([p.get() for p in processes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5156101636,\n",
       " 2040509584,\n",
       " 489869689,\n",
       " 2564409600,\n",
       " 2630971849,\n",
       " 866772481,\n",
       " 10758400,\n",
       " 293265625,\n",
       " 220581904,\n",
       " 1292043025]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
