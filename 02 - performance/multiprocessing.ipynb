{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing US_category_id.json\n",
      "processing JPvideos.csv\n",
      "processing KR_category_id.json\n",
      "processing MX_category_id.json\n",
      "processing MXvideos.csv\n",
      "processing DE_category_id.json\n",
      "processing KRvideos.csv\n",
      "processing FRvideos.csv\n",
      "processing CA_category_id.json\n",
      "processing RUvideos.csv\n",
      "processing GB_category_id.json\n",
      "processing GBvideos.csv\n",
      "processing FR_category_id.json\n",
      "processing IN_category_id.json\n",
      "processing USvideos.csv\n",
      "processing JP_category_id.json\n",
      "processing RU_category_id.json\n",
      "processing CAvideos.csv\n",
      "processing DEvideos.csv\n",
      "processing INvideos.csv\n"
     ]
    }
   ],
   "source": [
    "# we use the same loading code\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import io\n",
    "import json\n",
    "\n",
    "countries = {}\n",
    "categories = {}\n",
    "\n",
    "with zipfile.ZipFile(\"../datasets/youtube-new.zip\") as z:\n",
    "    for file in z.filelist:\n",
    "        print(f'processing {file.filename}')\n",
    "        key = file.filename.split('.')[0]        \n",
    "        if file.filename.endswith('.csv'):\n",
    "            with z.open(file.filename) as f:\n",
    "                countries[key] = pd.read_csv(io.StringIO(f.read().decode('latin-1')))\n",
    "        if file.filename.endswith('.json'):                \n",
    "            with z.open(file.filename) as f:\n",
    "                categories[key] = json.loads(f.read())\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our aggregation function\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def unique_tags(x, top: int=10):\n",
    "    print('starting unique tags function')\n",
    "    # split by '|'\n",
    "    res = x.apply(lambda x: x.split('|')) \n",
    "    # flatten in single list\n",
    "    flat = [elem.strip('\"') for row in res for elem in row]\n",
    "    # return a set (so it keeps only unique elements)\n",
    "    return Counter(flat).most_common(top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting unique tags function\n",
      "starting unique tags function\n",
      "created a cpu pool with 2 CPUs\n",
      "Creating tasks\n",
      "Closing the pool, processes are starting now\n",
      "Blocks Execution until all processes in the pool are done\n",
      "starting unique tags function\n",
      "starting unique tags function\n",
      "starting unique tags function\n",
      "starting unique tags function\n",
      "starting unique tags function\n",
      "starting unique tags function\n",
      "starting unique tags function\n",
      "starting unique tags function\n",
      "Displaying results\n",
      "[[('[none]', 3200), ('æ\\x96\\x99ç\\x90\\x86', 800), ('ã\\x81\\x8aã\\x82\\x82ã\\x81\\x97ã\\x82\\x8d', 675), ('ã\\x83\\x8bã\\x83¥ã\\x83¼ã\\x82¹', 592), ('ç\\x8c«', 591), ('ã\\x81\\x8aç¬\\x91ã\\x81\\x84', 571), ('ã\\x82¢ã\\x83\\x8bã\\x83¡', 530), ('ã\\x81\\x8bã\\x82\\x8fã\\x81\\x84ã\\x81\\x84', 484), ('é\\x87£ã\\x82\\x8a', 480), ('å¤§é£\\x9fã\\x81\\x84', 444), ('é\\x9d¢ç\\x99½', 443), ('funny', 440), ('cat', 430), ('ã\\x82²ã\\x83¼ã\\x83\\xa0', 427), ('å\\x8b\\x95ç\\x94»', 419), ('ç\\x88\\x86ç¬\\x91', 411), ('å\\x8f¯æ\\x84\\x9bã\\x81\\x84', 388), ('è¡\\x9dæ\\x92\\x83', 384), ('UUUM', 381), ('é\\x9d¢ç\\x99½ã\\x81\\x84', 373), ('å®\\x9fæ³\\x81', 355), ('japanese', 355), ('YouTuber', 355), ('ã\\x83¬ã\\x82·ã\\x83\\x94', 342), ('é\\x83½å¸\\x82ä¼\\x9dèª¬', 342)], [('[none]', 7685), ('2018', 1698), ('noticias', 1299), ('mexico', 1253), ('Televisa', 906), ('2017', 795), ('tv azteca', 788), ('de', 755), ('comedia', 703), ('espaÃ±ol', 680), ('viral', 677), ('video', 663), ('amor', 657), ('humor', 600), ('entretenimiento', 583), ('top', 581), ('famosos', 569), ('futbol', 559), ('funny', 556), ('amlo', 555), ('videos', 549), ('Noticias', 525), ('televisa', 514), ('tops', 491), ('MÃ©xico', 480)], [('[none]', 7183), ('ë¨¹ë°©', 2046), ('ë¬¸ì\\x9e¬ì\\x9d¸', 1797), ('ë\\x89´ì\\x8a¤', 1296), ('ê¹\\x80ì\\xa0\\x95ì\\x9d\\x80', 1007), ('ì²\\xa0êµ¬', 989), ('ë¦¬ë·°', 969), ('í\\x8a¸ë\\x9f¼í\\x94\\x84', 879), ('ì\\x98\\x81í\\x99\\x94', 781), ('ë°\\x95ê·¼í\\x98\\x9c', 778), ('mukbang', 756), ('ë°©í\\x83\\x84ì\\x86\\x8cë\\x85\\x84ë\\x8b¨', 744), ('ë\\x8c\\x80ë\\x8f\\x84ì\\x84\\x9cê´\\x80', 691), ('ê¿\\x80ì\\x9e¼', 677), ('ì\\x9d´ëª\\x85ë°\\x95', 669), ('í\\x99\\x8dì¤\\x80í\\x91\\x9c', 669), ('ë°´ì¯\\x94', 654), ('ë\\xa0\\x88ì\\xa0\\x84ë\\x93\\x9c', 653), ('ë¶\\x81í\\x95\\x9c', 640), ('ì\\x9e\\x90ì\\x9c\\xa0í\\x95\\x9cêµ\\xadë\\x8b¹', 632), ('í\\x95\\x9cêµ\\xad', 630), ('ë¯¸êµ\\xad', 610), ('ì\\x9b\\x83ê¸´', 583), ('ê¹\\x80ì\\x96´ì¤\\x80', 578), ('ì\\x9b\\x8cë\\x84\\x88ì\\x9b\\x90', 570)], [('[none]', 5304), ('humour', 2034), ('2018', 1489), ('football', 1176), ('france', 835), ('2017', 628), ('rap', 627), ('video', 614), ('divertissement', 609), ('musique', 603), ('live', 602), ('tv', 596), ('freestyle', 552), ('interview', 550), ('funny', 539), ('France', 524), ('foot', 514), ('senegal', 482), ('paris', 468), ('drole', 466), ('franÃ§ais', 461), ('sport', 461), ('vidÃ©o', 456), ('sketch', 447), ('amour', 433)], [('[none]', 3984), ('Ñ\\x8eÐ¼Ð¾Ñ\\x80', 1914), ('Ð½Ð¾Ð²Ð¾Ñ\\x81Ñ\\x82Ð¸', 1795), ('2018', 1671), ('Ð¾Ð±Ð·Ð¾Ñ\\x80', 1639), ('Ð¿Ð¾Ð»Ð¸Ñ\\x82Ð¸ÐºÐ°', 1629), ('Ð¿Ñ\\x83Ñ\\x82Ð¸Ð½', 1411), ('Ñ\\x80Ð¾Ñ\\x81Ñ\\x81Ð¸Ñ\\x8f', 1168), ('Ð\\xa0Ð¾Ñ\\x81Ñ\\x81Ð¸Ñ\\x8f', 1167), ('Ð\\x9fÑ\\x83Ñ\\x82Ð¸Ð½', 1058), ('Ð¿Ñ\\x80Ð¸ÐºÐ¾Ð»Ñ\\x8b', 1034), ('Ñ\\x82Ð¾Ð¿', 1014), ('Ð²Ñ\\x8bÐ±Ð¾Ñ\\x80Ñ\\x8b', 885), ('Ñ\\x88Ð¾Ñ\\x83', 775), ('2017', 762), ('Ð¿Ñ\\x80Ð¸ÐºÐ¾Ð»', 751), ('Ñ\\x81Ð²Ð¾Ð¸Ð¼Ð¸ Ñ\\x80Ñ\\x83ÐºÐ°Ð¼Ð¸', 716), ('Ñ\\x8dÐºÐ¾Ð½Ð¾Ð¼Ð¸ÐºÐ°', 679), ('Ð¿Ð¾Ñ\\x81Ð»ÐµÐ´Ð½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ñ\\x81Ñ\\x82Ð¸', 660), ('Ð²Ð¸Ð´ÐµÐ¾', 653), ('ÐºÐ¸Ð½Ð¾', 616), ('Ñ\\x81ÐµÑ\\x80Ð¸Ð°Ð»', 596), ('ÐºÐ»Ð¸Ð¿', 593), ('Ñ\\x83Ð³Ð°Ñ\\x80', 584), ('Ñ\\x84Ð°ÐºÑ\\x82Ñ\\x8b', 583)], [('funny', 2629), ('comedy', 2322), ('[none]', 2010), ('music', 1972), ('Pop', 1556), ('2018', 1383), ('video', 1189), ('music video', 1159), ('Records', 1137), ('interview', 1124), ('official', 1106), ('humor', 1072), ('live', 1011), ('Rap', 987), ('vlog', 959), ('trailer', 940), ('movie', 867), ('hip hop', 857), ('celebrity', 833), ('Music', 831), ('comedian', 820), ('Trailer', 784), ('rap', 756), ('2017', 754), ('late night', 749)], [('funny', 3603), ('comedy', 2931), ('how to', 1604), ('[none]', 1535), ('music', 1302), ('Pop', 1280), ('2018', 1275), ('humor', 1185), ('food', 1159), ('science', 1111), ('review', 1005), ('makeup', 990), ('news', 988), ('celebrity', 930), ('vlog', 928), ('video', 890), ('tutorial', 864), ('live', 862), ('comedian', 861), ('interview', 845), ('cooking', 802), ('television', 779), ('celebrities', 769), ('fun', 737), ('movie', 734)], [('funny', 3416), ('comedy', 2432), ('[none]', 2385), ('news', 1452), ('2018', 1147), ('video', 1034), ('politics', 1010), ('humor', 959), ('food', 915), ('review', 911), ('music', 875), ('reaction', 854), ('2017', 767), ('family friendly', 764), ('talk show', 757), ('interview', 750), ('comedian', 730), ('donald trump', 693), ('News', 675), ('trump', 660), ('funny videos', 655), ('react', 637), ('Donald Trump', 634), ('television', 627), ('how to', 622)], [('[none]', 3031), ('2018', 1399), ('funny', 1232), ('comedy', 1192), ('deutsch', 1122), ('TV', 1064), ('tv', 911), ('german', 734), ('2017', 722), ('news', 708), ('atv', 689), ('dizi', 671), ('lustig', 645), ('music', 585), ('rap', 565), ('Deutschland', 560), ('star tv', 512), ('essen', 509), ('Comedy', 506), ('Reality TV', 505), ('humor', 497), ('review', 496), ('SAT.1', 493), ('video', 490), ('Highlights', 478)], [('comedy', 2384), ('funny', 2129), ('television', 1414), ('show', 1400), ('[none]', 1381), ('serial', 1330), ('full episode', 1303), ('funny videos', 1249), ('daily soap', 1235), ('watch online', 1229), ('latest news', 994), ('2018', 958), ('news', 919), ('jabardasth', 898), ('India', 836), ('bollywood', 820), ('entertainment', 806), ('telugu', 805), ('punjabi songs', 786), ('extra jabardasth', 783), ('latest', 772), ('india', 772), ('Zee5', 766), ('hindi', 765), ('breaking news', 697)]]\n"
     ]
    }
   ],
   "source": [
    "# Parallel processing with Pool.apply_async()\n",
    "\n",
    "import multiprocessing as mp\n",
    "cpu_count = mp.cpu_count()\n",
    "pool = mp.Pool(cpu_count)\n",
    "print(f'created a cpu pool with {cpu_count} CPUs')\n",
    "\n",
    "\n",
    "results = []\n",
    "print('Creating tasks')\n",
    "for country, df in countries.items():\n",
    "    results.append(pool.apply_async(unique_tags, args=(df['tags'], 25))\n",
    "                    )                                                 \n",
    "print('Closing the pool, processes are starting now')\n",
    "pool.close()\n",
    "print('Blocks Execution until all processes in the pool are done')\n",
    "pool.join() \n",
    "\n",
    "print('Displaying results')\n",
    "output = [p.get() for p in results]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix: How do we know which country ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_tags_mp(country, x, top: int=10):\n",
    "    print(f'starting unique tags function {country}')\n",
    "    # split by '|'\n",
    "    res = x.apply(lambda x: x.split('|')) \n",
    "    # flatten in single list\n",
    "    flat = [elem.strip('\"') for row in res for elem in row]\n",
    "    # return a set (so it keeps only unique elements)\n",
    "    print(f'done with {country}')\n",
    "    return {country: Counter(flat).most_common(top)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting unique tags function JPvideos\n",
      "starting unique tags function MXvideos\n",
      "created a cpu pool with 2 CPUs\n",
      "Creating tasks\n",
      "Closing the pool, processes are starting now\n",
      "Blocks Execution until all processes in the pool are done\n",
      "done with JPvideos\n",
      "starting unique tags function KRvideos\n",
      "done with MXvideos\n",
      "done with KRvideos\n",
      "starting unique tags function FRvideos\n",
      "done with FRvideos\n",
      "starting unique tags function RUvideos\n",
      "starting unique tags function GBvideos\n",
      "done with RUvideos\n",
      "done with GBvideos\n",
      "starting unique tags function USvideos\n",
      "starting unique tags function CAvideos\n",
      "done with USvideos\n",
      "done with CAvideos\n",
      "starting unique tags function DEvideos\n",
      "starting unique tags function INvideos\n",
      "done with DEvideos\n",
      "done with INvideos\n",
      "Displaying results\n",
      "{'JPvideos': [('[none]', 3200), ('æ\\x96\\x99ç\\x90\\x86', 800), ('ã\\x81\\x8aã\\x82\\x82ã\\x81\\x97ã\\x82\\x8d', 675), ('ã\\x83\\x8bã\\x83¥ã\\x83¼ã\\x82¹', 592), ('ç\\x8c«', 591), ('ã\\x81\\x8aç¬\\x91ã\\x81\\x84', 571), ('ã\\x82¢ã\\x83\\x8bã\\x83¡', 530), ('ã\\x81\\x8bã\\x82\\x8fã\\x81\\x84ã\\x81\\x84', 484), ('é\\x87£ã\\x82\\x8a', 480), ('å¤§é£\\x9fã\\x81\\x84', 444), ('é\\x9d¢ç\\x99½', 443), ('funny', 440), ('cat', 430), ('ã\\x82²ã\\x83¼ã\\x83\\xa0', 427), ('å\\x8b\\x95ç\\x94»', 419), ('ç\\x88\\x86ç¬\\x91', 411), ('å\\x8f¯æ\\x84\\x9bã\\x81\\x84', 388), ('è¡\\x9dæ\\x92\\x83', 384), ('UUUM', 381), ('é\\x9d¢ç\\x99½ã\\x81\\x84', 373), ('å®\\x9fæ³\\x81', 355), ('japanese', 355), ('YouTuber', 355), ('ã\\x83¬ã\\x82·ã\\x83\\x94', 342), ('é\\x83½å¸\\x82ä¼\\x9dèª¬', 342)], 'MXvideos': [('[none]', 7685), ('2018', 1698), ('noticias', 1299), ('mexico', 1253), ('Televisa', 906), ('2017', 795), ('tv azteca', 788), ('de', 755), ('comedia', 703), ('espaÃ±ol', 680), ('viral', 677), ('video', 663), ('amor', 657), ('humor', 600), ('entretenimiento', 583), ('top', 581), ('famosos', 569), ('futbol', 559), ('funny', 556), ('amlo', 555), ('videos', 549), ('Noticias', 525), ('televisa', 514), ('tops', 491), ('MÃ©xico', 480)], 'KRvideos': [('[none]', 7183), ('ë¨¹ë°©', 2046), ('ë¬¸ì\\x9e¬ì\\x9d¸', 1797), ('ë\\x89´ì\\x8a¤', 1296), ('ê¹\\x80ì\\xa0\\x95ì\\x9d\\x80', 1007), ('ì²\\xa0êµ¬', 989), ('ë¦¬ë·°', 969), ('í\\x8a¸ë\\x9f¼í\\x94\\x84', 879), ('ì\\x98\\x81í\\x99\\x94', 781), ('ë°\\x95ê·¼í\\x98\\x9c', 778), ('mukbang', 756), ('ë°©í\\x83\\x84ì\\x86\\x8cë\\x85\\x84ë\\x8b¨', 744), ('ë\\x8c\\x80ë\\x8f\\x84ì\\x84\\x9cê´\\x80', 691), ('ê¿\\x80ì\\x9e¼', 677), ('ì\\x9d´ëª\\x85ë°\\x95', 669), ('í\\x99\\x8dì¤\\x80í\\x91\\x9c', 669), ('ë°´ì¯\\x94', 654), ('ë\\xa0\\x88ì\\xa0\\x84ë\\x93\\x9c', 653), ('ë¶\\x81í\\x95\\x9c', 640), ('ì\\x9e\\x90ì\\x9c\\xa0í\\x95\\x9cêµ\\xadë\\x8b¹', 632), ('í\\x95\\x9cêµ\\xad', 630), ('ë¯¸êµ\\xad', 610), ('ì\\x9b\\x83ê¸´', 583), ('ê¹\\x80ì\\x96´ì¤\\x80', 578), ('ì\\x9b\\x8cë\\x84\\x88ì\\x9b\\x90', 570)], 'FRvideos': [('[none]', 5304), ('humour', 2034), ('2018', 1489), ('football', 1176), ('france', 835), ('2017', 628), ('rap', 627), ('video', 614), ('divertissement', 609), ('musique', 603), ('live', 602), ('tv', 596), ('freestyle', 552), ('interview', 550), ('funny', 539), ('France', 524), ('foot', 514), ('senegal', 482), ('paris', 468), ('drole', 466), ('franÃ§ais', 461), ('sport', 461), ('vidÃ©o', 456), ('sketch', 447), ('amour', 433)], 'RUvideos': [('[none]', 3984), ('Ñ\\x8eÐ¼Ð¾Ñ\\x80', 1914), ('Ð½Ð¾Ð²Ð¾Ñ\\x81Ñ\\x82Ð¸', 1795), ('2018', 1671), ('Ð¾Ð±Ð·Ð¾Ñ\\x80', 1639), ('Ð¿Ð¾Ð»Ð¸Ñ\\x82Ð¸ÐºÐ°', 1629), ('Ð¿Ñ\\x83Ñ\\x82Ð¸Ð½', 1411), ('Ñ\\x80Ð¾Ñ\\x81Ñ\\x81Ð¸Ñ\\x8f', 1168), ('Ð\\xa0Ð¾Ñ\\x81Ñ\\x81Ð¸Ñ\\x8f', 1167), ('Ð\\x9fÑ\\x83Ñ\\x82Ð¸Ð½', 1058), ('Ð¿Ñ\\x80Ð¸ÐºÐ¾Ð»Ñ\\x8b', 1034), ('Ñ\\x82Ð¾Ð¿', 1014), ('Ð²Ñ\\x8bÐ±Ð¾Ñ\\x80Ñ\\x8b', 885), ('Ñ\\x88Ð¾Ñ\\x83', 775), ('2017', 762), ('Ð¿Ñ\\x80Ð¸ÐºÐ¾Ð»', 751), ('Ñ\\x81Ð²Ð¾Ð¸Ð¼Ð¸ Ñ\\x80Ñ\\x83ÐºÐ°Ð¼Ð¸', 716), ('Ñ\\x8dÐºÐ¾Ð½Ð¾Ð¼Ð¸ÐºÐ°', 679), ('Ð¿Ð¾Ñ\\x81Ð»ÐµÐ´Ð½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ñ\\x81Ñ\\x82Ð¸', 660), ('Ð²Ð¸Ð´ÐµÐ¾', 653), ('ÐºÐ¸Ð½Ð¾', 616), ('Ñ\\x81ÐµÑ\\x80Ð¸Ð°Ð»', 596), ('ÐºÐ»Ð¸Ð¿', 593), ('Ñ\\x83Ð³Ð°Ñ\\x80', 584), ('Ñ\\x84Ð°ÐºÑ\\x82Ñ\\x8b', 583)], 'GBvideos': [('funny', 2629), ('comedy', 2322), ('[none]', 2010), ('music', 1972), ('Pop', 1556), ('2018', 1383), ('video', 1189), ('music video', 1159), ('Records', 1137), ('interview', 1124), ('official', 1106), ('humor', 1072), ('live', 1011), ('Rap', 987), ('vlog', 959), ('trailer', 940), ('movie', 867), ('hip hop', 857), ('celebrity', 833), ('Music', 831), ('comedian', 820), ('Trailer', 784), ('rap', 756), ('2017', 754), ('late night', 749)], 'USvideos': [('funny', 3603), ('comedy', 2931), ('how to', 1604), ('[none]', 1535), ('music', 1302), ('Pop', 1280), ('2018', 1275), ('humor', 1185), ('food', 1159), ('science', 1111), ('review', 1005), ('makeup', 990), ('news', 988), ('celebrity', 930), ('vlog', 928), ('video', 890), ('tutorial', 864), ('live', 862), ('comedian', 861), ('interview', 845), ('cooking', 802), ('television', 779), ('celebrities', 769), ('fun', 737), ('movie', 734)], 'CAvideos': [('funny', 3416), ('comedy', 2432), ('[none]', 2385), ('news', 1452), ('2018', 1147), ('video', 1034), ('politics', 1010), ('humor', 959), ('food', 915), ('review', 911), ('music', 875), ('reaction', 854), ('2017', 767), ('family friendly', 764), ('talk show', 757), ('interview', 750), ('comedian', 730), ('donald trump', 693), ('News', 675), ('trump', 660), ('funny videos', 655), ('react', 637), ('Donald Trump', 634), ('television', 627), ('how to', 622)], 'DEvideos': [('[none]', 3031), ('2018', 1399), ('funny', 1232), ('comedy', 1192), ('deutsch', 1122), ('TV', 1064), ('tv', 911), ('german', 734), ('2017', 722), ('news', 708), ('atv', 689), ('dizi', 671), ('lustig', 645), ('music', 585), ('rap', 565), ('Deutschland', 560), ('star tv', 512), ('essen', 509), ('Comedy', 506), ('Reality TV', 505), ('humor', 497), ('review', 496), ('SAT.1', 493), ('video', 490), ('Highlights', 478)], 'INvideos': [('comedy', 2384), ('funny', 2129), ('television', 1414), ('show', 1400), ('[none]', 1381), ('serial', 1330), ('full episode', 1303), ('funny videos', 1249), ('daily soap', 1235), ('watch online', 1229), ('latest news', 994), ('2018', 958), ('news', 919), ('jabardasth', 898), ('India', 836), ('bollywood', 820), ('entertainment', 806), ('telugu', 805), ('punjabi songs', 786), ('extra jabardasth', 783), ('latest', 772), ('india', 772), ('Zee5', 766), ('hindi', 765), ('breaking news', 697)]}\n"
     ]
    }
   ],
   "source": [
    "# Parallel processing with Pool.apply_async()\n",
    "cpu_count = mp.cpu_count()\n",
    "pool = mp.Pool(cpu_count)\n",
    "print(f'created a cpu pool with {cpu_count} CPUs')\n",
    "\n",
    "\n",
    "results = []\n",
    "print('Creating tasks')\n",
    "for country, df in countries.items():\n",
    "    results.append(pool.apply_async(unique_tags_mp, args=(country, df['tags'], 25))\n",
    "                    )                                                 \n",
    "print('Closing the pool, processes are starting now')\n",
    "pool.close()\n",
    "print('Blocks Execution until all processes in the pool are done')\n",
    "pool.join() \n",
    "\n",
    "print('Displaying results')\n",
    "output =  {}\n",
    "for p in results:\n",
    "    output.update(p.get())\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. For each of the top 25 tags (worldwide), calculate the ratios: like, dislike & comments (by view)\n",
    "\n",
    "\n",
    "#### _if we have time_\n",
    "    \n",
    "Steps:\n",
    "1. Aggregate results from the exercise above to find the top25 worldwide tags\n",
    "2. Create a multiprocessing job to get the like, dislikes, comments, views aggregated by tag for each country\n",
    "3. Aggregate the results\n",
    "4. Compute ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
